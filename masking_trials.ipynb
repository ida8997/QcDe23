{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_napari(images, labels):\n",
    "    \"\"\" Visualize all images in list using napari\n",
    "    parameters\n",
    "    ----------\n",
    "    imagest: list of numpy images\n",
    "    labels: list of names for each image\n",
    "        \"\"\"\n",
    "    viewer = napari.Viewer()\n",
    "    for i, img in enumerate(images):\n",
    "        viewer.add_image(img, name=labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv.imread('DE_annotated_pictures/20220202_547 D4 001_ch00_yn.tif')\n",
    "img = cv.imread('DE_annotated_pictures/20220918_812 100ml D4001_ch00_yn.tif')\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(img, rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1944, 2592, 3) (1944, 2592, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'img2' at 0x2ed6440d0c0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = cv.imread('DE_annotated_pictures/20220528_703 D4 001_ch00_yn.tif')\n",
    "img2 = cv.imread('DE_annotated_pictures/20220918_811 D4001_ch00_yn.tif')\n",
    "print(img1.shape, img2.shape)\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img1)\n",
    "viewer.add_image(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "# viewer.add_image(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = np.array([0, 0, 0])\n",
    "high = np.array([200, 180, 105])\n",
    "mask_inRange = cv.inRange(img, low, high)\n",
    "masked_img = cv.bitwise_and(img, img, mask=mask_inRange)\n",
    "# viewer.add_image(mask_inRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDimage = img.reshape((-1,3))\n",
    "twoDimage = np.float32(twoDimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "attempts = 10\n",
    "\n",
    "ret1, label1, center1 = cv.kmeans(twoDimage, 2, None, criteria, attempts, cv.KMEANS_PP_CENTERS)\n",
    "ret2, label2, center2 = cv.kmeans(twoDimage, 3, None, criteria, attempts, cv.KMEANS_PP_CENTERS)\n",
    "ret3, label3, center3 = cv.kmeans(twoDimage, 4, None, criteria, attempts, cv.KMEANS_PP_CENTERS)\n",
    "\n",
    "center1 = np.uint8(center1)\n",
    "res1 = center1[label1.flatten()]\n",
    "mask_2nn = res1.reshape((img.shape))\n",
    "\n",
    "center2 = np.uint8(center2)\n",
    "res2 = center2[label2.flatten()]\n",
    "mask_3nn = res2.reshape((img.shape))\n",
    "\n",
    "center3 = np.uint8(center3)\n",
    "res3 = center3[label3.flatten()]\n",
    "mask_4nn = res3.reshape((img.shape))\n",
    "\n",
    "# viewer.add_image(mask_2nn)\n",
    "# viewer.add_image(mask_3nn)\n",
    "# viewer.add_image(mask_4nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, thresh = cv.threshold(gray_img, np.mean(gray_img), 255, cv.THRESH_BINARY_INV)\n",
    "edges = cv.dilate(cv.Canny(thresh, 0, 255), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = cv.getStructuringElement(cv.MORPH_RECT, (3,3))\n",
    "kernel2 = cv.getStructuringElement(cv.MORPH_ELLIPSE, (4,4))\n",
    "\n",
    "erosion = cv.erode(thresh, kernel2, iterations = 5)\n",
    "opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel2)\n",
    "closing = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel2)\n",
    "dilation = cv.dilate(thresh, kernel2, iterations = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'erosion' at 0x2ed4b8dbfa0>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img)\n",
    "viewer.add_image(thresh)\n",
    "viewer.add_image(erosion)\n",
    "# viewer.add_image(opening) \n",
    "# viewer.add_image(closing)\n",
    "# viewer.add_image(dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_adpt_m = cv.adaptiveThreshold(gray_img, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 25, 10)\n",
    "thresh_adpt_g = cv.adaptiveThreshold(gray_img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, -10)\n",
    "dilation = cv.dilate(thresh_adpt_m, kernel1, iterations = 1)\n",
    "opening = cv.morphologyEx(thresh_adpt_m, cv.MORPH_OPEN, kernel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'img' at 0x2ed34103bb0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(thresh_adpt_m)\n",
    "viewer.add_image(dilation)\n",
    "viewer.add_image(opening)\n",
    "viewer.add_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewer.add_image(th2)\n",
    "# viewer.add_image(th3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "th_otsu = threshold_otsu(gray_img)\n",
    "thresh_otsu  = gray_img < th_otsu\n",
    "\n",
    "# viewer.add_image(img_otsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "imgs = [img, gray_img, mask_inRange, thresh, opening, closing, dilation, thresh_adpt_m, thresh_adpt_g, thresh_otsu]\n",
    "labels = ['original', 'grayscale', 'color masking', 'global thresholding', \n",
    "          'opening', 'opened and closed', 'opened and dilated',\n",
    "          'adaptive mean thresholding', 'adpative gaussian thresholding', 'otsu thresholding']\n",
    "print(len(imgs), len(labels))\n",
    "visualize_napari(imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels, labels, stats, centroids = cv.connectedComponentsWithStats(erosion, connectivity=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stats(labels, stats, centroids):\n",
    "    \"\"\"\n",
    "    Delete connected components that are too small or too large.\n",
    "    \"\"\"\n",
    "    labels_cp = labels.copy()\n",
    "    stats_cp = stats.copy()\n",
    "    centroids_cp = centroids.copy()\n",
    "    indices = []\n",
    "\n",
    "    for i in range(0, stats.shape[0]):\n",
    "        if stats[i, 4] < 200:\n",
    "            indices.append(i)\n",
    "        elif stats[i, 4] > 300**2:\n",
    "            indices.append(i)\n",
    "        elif not(0.7 <= stats[i,2] / stats[i,3] <= 1.3):\n",
    "            indices.append(i)\n",
    "    \n",
    "    labels_cp = labels_cp * ~(np.in1d(labels_cp, indices).reshape(labels_cp.shape))\n",
    "    stats_cp = np.delete(stats_cp, indices, axis=0)\n",
    "    centroids_cp = np.delete(centroids_cp, indices, axis=0)\n",
    "    return labels_cp, stats_cp, centroids_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlabels, tstats, tcentroids = clean_stats(labels, stats, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 5)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bounding_boxes(img, stats, labels, centroids):\n",
    "    \"\"\"\n",
    "    Add rectangles around objects\n",
    "    \"\"\"\n",
    "    labels_cp = labels.copy()\n",
    "    stats_cp = stats.copy()\n",
    "    centroids_cp = centroids.copy()\n",
    "    indices = []\n",
    "    img_copy = img.copy()\n",
    "    \n",
    "    for i in range(0, stats.shape[0]):\n",
    "        # discard component if too small indicating noise or holes within components\n",
    "        if stats[i, 4] < 200:\n",
    "            indices.append(i)\n",
    "            continue\n",
    "        # color box red if component too big indicating two components being attached to each other\n",
    "        # or if ratio between width and height of component outside tolerance \n",
    "        # indicating two components being attached to each other or component being at boundary and thus cropped\n",
    "        elif stats[i, 4] > 300**2 or not(0.7 <= stats[i,2] / stats[i,3] <= 1.3):\n",
    "            indices.append(i)\n",
    "            x = stats[i, 0] - 10\n",
    "            y = stats[i, 1] - 10\n",
    "            w = stats[i, 2] + 20\n",
    "            h = stats[i, 3] + 20\n",
    "            cv.rectangle(img_copy, (x, y), (x + w, y + h), (255, 0, 0), 3)\n",
    "        # discard component if at boundary\n",
    "        elif np.min(np.where(labels == i)[0]) == 0 or np.min(np.where(labels == i)[1]) == 0 \\\n",
    "            or np.max(np.where(labels == i)[0]) == 1943 or np.max(np.where(labels == i)[1]) == 2591:\n",
    "            indices.append(i)\n",
    "            x = stats[i, 0] - 10\n",
    "            y = stats[i, 1] - 10\n",
    "            w = stats[i, 2] + 20\n",
    "            h = stats[i, 3] + 20\n",
    "            cv.rectangle(img_copy, (x, y), (x + w, y + h), (255, 0, 0), 3)\n",
    "        # else, color box green\n",
    "        else:\n",
    "            x = stats[i, 0] - 10\n",
    "            y = stats[i, 1] - 10\n",
    "            w = stats[i, 2] + 20\n",
    "            h = stats[i, 3] + 20\n",
    "            cv.rectangle(img_copy, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "    \n",
    "    labels_cp = labels_cp * ~(np.in1d(labels_cp, indices).reshape(labels_cp.shape))\n",
    "    stats_cp = np.delete(stats_cp, indices, axis=0)\n",
    "    centroids_cp = np.delete(centroids_cp, indices, axis=0)\n",
    "    return img_copy, labels_cp, stats_cp, centroids_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1944, 2592, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_boxes, tlabels, tstats, tcentroids = add_bounding_boxes(img, stats, labels, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'erosion' at 0x20ef021ca60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img_with_boxes)\n",
    "viewer.add_image(erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_enclosing_ellipses(img, labels):\n",
    "    \"\"\"\n",
    "    Find and add enclosing ellipses around objects\n",
    "    ------------\n",
    "    labels: contains only labels of \"valid\" components\n",
    "    \"\"\"\n",
    "    img_copy = img.copy()\n",
    "    for i in np.unique(labels)[1:]:\n",
    "        points = np.where(labels == i)\n",
    "        points = np.transpose(points)\n",
    "        (xc, yc), (d1, d2), angle = cv.fitEllipse(points)\n",
    "        ellipse = ((int(yc), int(xc)), (int(d1), int(d2)), angle)\n",
    "        cv.ellipse(img_copy, ellipse, (0, 0, 255), 3)\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'img_with_ellipses' at 0x2ec8f380910>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_with_ellipses = find_enclosing_ellipses(img, tlabels)\n",
    "viewer.add_image(img_with_ellipses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
